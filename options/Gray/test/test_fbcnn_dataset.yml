# CUDA_VISIBLE_DEVICES=2,3 python oapt/test.py -opt ./options/Gray/test/test_fbcnn_dataset.yml
name: test_fbcnn_gray
model_type: MYModelB
scale: 1
num_gpu: 1
manual_seed: 0


# tile: # use the tile mode for limited GPU memory when testing.
#   tile_size: 224 # the higher, the more utilized GPU memory and the less performance change against the full image. must be an integer multiple of the window size.
#   tile_pad: 16 # overlapping between adjacency patches.must be an integer multiple of the window size.


datasets:
  test_1:
    name: Classic5_3030_offset4
    type: DoubleJpegImageDataset
    dataroot_gt: ./dataset/Classic5
    dataroot_lq: ./dataset/Classic5
    io_backend:
      type: disk
    # num_channels: 3
    num_channels: 1
    color: y
    quality_factor: 30
    double_compression: true 
    second_qfs: 30 
    shift_w: 4 
    shift_h: 4 



  

# network structures
network_g:
  type: FBCNN
  in_nc: 1
  out_nc: 1
  nc: [64,128,256,512]
  nb: 4
  act_mode: 'R'
  


# path
path:
  pretrain_network_g: models_zoo/non_aligned/fbcnn_gray_double.pth
  strict_load_g: True
  param_key_g: ~



# validation settings
val:
  save_img: false
  suffix: ~  # add suffix to saved images, if None, use exp name
  pbar: True

  metrics:
    psnr: # metric name, can be arbitrary
      type: calculate_psnr
      crop_border: 0
      test_y_channel: False
    ssim:
      type: calculate_ssim
      crop_border: 0
      test_y_channel: False
# https://torchmetrics.readthedocs.io/en/stable/image/peak_signal_to_noise_with_block.html